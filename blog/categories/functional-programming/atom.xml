<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Functional Programming | Logan McGrath's Blog]]></title>
  <link href="http://loganmcgrath.com/blog/categories/functional-programming/atom.xml" rel="self"/>
  <link href="http://loganmcgrath.com/"/>
  <updated>2015-03-08T14:48:04-07:00</updated>
  <id>http://loganmcgrath.com/</id>
  <author>
    <name><![CDATA[Logan McGrath]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Scoping And Thunking In Let Declarations]]></title>
    <link href="http://loganmcgrath.com/blog/2015/01/23/scoping-and-thunking-in-let-declarations/"/>
    <updated>2015-01-23T08:30:00-08:00</updated>
    <id>http://loganmcgrath.com/blog/2015/01/23/scoping-and-thunking-in-let-declarations</id>
    <content type="html"><![CDATA[<p>I haven&rsquo;t stopped fiddling with language development. Actually, I still do it
almost full-time in my free time. My latest prototype,
<a href="https://github.com/lmcgrath/scotch-lang">Scotch</a>, which uses Haskell-like syntax
and semantics, is coming close to a point where I can start developing the main
libraries. Close, but there are a few kinks. Here I&rsquo;ll be covering an issue I&rsquo;m
having with <code>let</code> declarations.</p>

<!--more-->


<p>Specifically, what I&rsquo;m struggling to get my head around is how to model scoping
of values declared within <code>let</code> declarations. (<em>Read about <code>let</code> declarations in
<a href="http://learnyouahaskell.com/syntax-in-functions#let-it-be">Learn You A Haskell</a>.</em>)</p>

<p>In this code, the child declaration <code>y</code> uses child declaration <code>z</code>, which is
used by the body of the <code>let</code>. Consider for a moment: What if <code>z</code> had side
effects?</p>

<p>```haskell Scotch Let Declaration
f :: s &ndash;> (a, s)
f x = let y = something with z</p>

<pre><code>      z = something else
      in do things with y and then z again
</code></pre>

<p>```</p>

<h2>How Are Side Effects A Problem In Child Scopes?</h2>

<p>Scotch is compiled into JVM bytecode. Value and function declarations are
encoded as static methods returning Java 8 lambdas. The declarations internally
use <a href="http://stackoverflow.com/questions/2641489/what-is-a-thunk">thunks</a> to
suspend evaluation but also to retain the evaluated result.</p>

<p>```java Scotch &ldquo;add&rdquo; Function Encoded As Static Java Method
// What x + y would look like compiled:
//
// This uses the runtime support functions applicable() and callable() to
// automatically generate the relevant thunk types.
public static Applicable&lt;Integer, Applicable&lt;Integer, Integer>> add() {
  return applicable(</p>

<pre><code>augend -&gt; applicable(
  addend -&gt; callable(
    () -&gt; augend.call() + addend.call()
  )
)
</code></pre>

<p>  );
}
```</p>

<p>```java What A Thunk Looks Like
public abstract class Thunk<A> implements Callable<A> {
  private A value;</p>

<p>  public A call() {</p>

<pre><code>if (value == null) {
  value = evaluate();
}
return value;
</code></pre>

<p>  }</p>

<p>  protected abstract A evaluate();
}
```</p>

<p>The reason for using thunks is to support lazy evaluation. Arguments passed into
functions are not evaluated until they are referenced. This also comes with the
benefit that arguments are only ever evaluated once. Because child declarations
form <a href="http://en.wikipedia.org/wiki/Closure_%28computer_programming%29">closures</a>
over variables in their parent scope, this also ensures local variables are also
only evaluated once within these child declarations.</p>

<p>Top-level declarations, like values and functions, are encoded as static Java
methods. Each time they are referenced, a new thunk is returned. In <code>let</code> declarations,
this poses a problem because every time a declaration is referenced, it returns
a new thunk. Say for example we have a child declaration called &ldquo;username&rdquo; which
fetches a username from a database. Every time the associated thunk is referenced,
the database is hit:</p>

<p>```java What It Looks Like in Pseudo-Java
static String username() {
return new Thunk() { /<em> database query </em>/ }
}</p>

<p>static String greet(String msg) {
  log(&ldquo;greeting &rdquo; + username())
  return msg + &ldquo; &rdquo; + username() + &ldquo;!&rdquo;
}
```</p>

<p>This becomes a major problem in Scotch because the values with side-effects
look like variables!</p>

<p>```haskell What it looks like in Scotch
greet msg =</p>

<pre><code>let username = do
      something to get
      this from a database
in do
  log "greeting " ++ username
  msg ++ " " ++ username ++ "!"
</code></pre>

<p>```</p>

<h2>Modeling Let As A Function</h2>

<p>I&rsquo;ve been mulling around a few crazy ways to model <code>let</code> declarations. My favorite
so far is wrapping the <code>let</code> body up in a function, passing in all declarations as
arguments:</p>

<p><code>``java Psuedo-Java</code>let` Modeled With Values As Arguments
static String username() {
  return new Thunk() { /<em> database query </em>/ }
}</p>

<p>static String greet(String msg) {
  greet_(msg, username())
}</p>

<p>static String greet_(String msg, Thunk<String> username) {
  log(&ldquo;greeting&rdquo; + username.get())        // here it evaluates for the first time
  return msg + &ldquo; &rdquo; + username.get() + &ldquo;!&rdquo; // here it gets the value from the initial evaluation above
}
```</p>

<p>This leverages the existing way of modeling evaluation, but it&rsquo;s kinda ugly. For
the near term, this solution is decent, however it adds the overhead of extra
arguments being passed around. I&rsquo;m not entirely sure how this impacts runtime
performance in compiled code, though I would like another way of modeling <code>let</code>
declarations to compare side-by-side.</p>

<h2>Storing Nested Values As Variables</h2>

<p>I really like this method of modeling <code>let</code> because it behaves more like how a
<code>let</code> looks in source code. Instead of wrapping a <code>let</code> within another function,
the declarations are assigned to local variables:</p>

<p>```java Values As Variables In Pseudo-Java
static String username() {
  return new Thunk() { /<em> database query </em>/ }
}</p>

<p>static String greet(String msg) {
  var username = username()
  log(&ldquo;greeting &rdquo; + username)
  return msg + &ldquo; &rdquo; + username + &ldquo;!&rdquo;
}
```</p>

<p>I&rsquo;m not entirely sure what performance impact of variables in <code>let</code> would be
compared to using arguments. Either way, I would be calling the methods associated
with each declaration and storing them somewhere. The only thing saved is an
additional function call, so any gains in performance would be minuscule.</p>

<h2>Why The Indecision?</h2>

<p>I&rsquo;m not sure I&rsquo;m following the best ways to model <code>let</code>. And I also don&rsquo;t have
any immediate way to test either solution short of branching the code and spiking
out the two solutions. The tradeoffs aren&rsquo;t necessarily obvious, and I won&rsquo;t see
which one is better in the long term compared to the one not chosen.</p>

<p>Compilation is hard. Scotch uses a <a href="http://en.wikipedia.org/wiki/Multi-pass_compiler">multi-pass compiler</a>
with 12 steps currently, so adding a new language feature or changing an existing
one can be very arduous tasks. Ideally, I only want to implement <code>let</code> once.</p>

<p>I will be posting on progress and which solution I end up choosing, stay tuned.</p>

<h2>@TODO</h2>

<ul>
<li>Write-up on lexical scoping in Scotch.</li>
<li>Details on how Scotch compiles values and functions in Java 8 lambdas.</li>
<li>How simple, non-recursive closures are implemented.</li>
<li>Implementation of co-recursive closures.</li>
</ul>


<hr />

<h3>Links</h3>

<ul>
<li><a href="https://github.com/lmcgrath/scotch-lang">Scotch Source</a></li>
<li><a href="http://en.wikipedia.org/wiki/Multi-pass_compiler">Multi-pass Compiler</a></li>
<li><a href="http://en.wikipedia.org/wiki/Thunk">Thunks (Wikipedia)</a></li>
</ul>


<h3>Credits</h3>

<p>Thanks to my dear friend <a href="https://github.com/azagniotov">Alexander Zagniotov</a>
who took time out of his busy day to review my multiple drafts.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Lessons from Sterling]]></title>
    <link href="http://loganmcgrath.com/blog/2013/08/05/lessons-from-sterling/"/>
    <updated>2013-08-05T09:37:00-07:00</updated>
    <id>http://loganmcgrath.com/blog/2013/08/05/lessons-from-sterling</id>
    <content type="html"><![CDATA[<p>I&rsquo;ve spent the last seven months developing a language called <a href="https://github.com/lmcgrath/sterling">Sterling</a>.
Sterling was intended to be an untyped functional scripting language, something like lazily-evaluated, immutable
JavaScript. Last week I decided to shelve Sterling.</p>

<!--more-->


<h2>How Sterling Worked</h2>

<p>Sterling&rsquo;s evaluation model is very simple and I felt it held a lot of promise because it made the language very
flexible. Everything in Sterling is an expression. Some expressions accept a single argument&mdash;these were called
<em>lambdas</em>. All expressions also contain sub-expressions, which could be accessed as <em>attributes</em>. With a little sugar,
a bag of attributes could be made self-referencing and thus become an <em>object</em>.</p>

<p>```haskell An assortment of basic expression types
// a constant expression which takes no arguments
anExpression = 2 + 2</p>

<p>// lambda expressions take only 1 argument
aLambda = (x) &ndash;> 2 + x</p>

<p>// function expressions take more than 1 argument
aFunction = (x y) &ndash;> x * y</p>

<p>// an object expression with constructor
anObject = (constructorArg) &ndash;> object {</p>

<pre><code>madeWith: constructorArg,
</code></pre>

<p>}</p>

<p>// an object expression that behaves like a lambda after constructed
invokableObject = (constructorArg) &ndash;> object {</p>

<pre><code>madeWith: constructorArg,
invoke: (arg) -&gt; "Made with #{self.madeWith} and invoked with #{arg}",
</code></pre>

<p>}
```</p>

<p>Expressions could be built up to carry a high amount of capability. Because Sterling is untyped, decoration and
ducktyping are used heavily to compose ever more features into expressions.</p>

<p>Sterling was directly inspired by <a href="http://en.wikipedia.org/wiki/Lambda_calculus">Lambda Calculus</a>. This had an enormous
impact on the design of the language, the largest of which was how the language executed at runtime. Expressions in
Sterling are represented as trees and leaves. Top-level expressions have names, and they could be inserted into other
expressions by referencing those names.</p>

<p>``` haskell A recursive named expression looks like this:
fibonacci = (n) &ndash;> if n &lt;= 1 then</p>

<pre><code>                   n
               else
                   fibonacci (n - 1) + fibonacci (n - 2)
               end
</code></pre>

<p>```</p>

<p>Because each expression was a tree, no expression needed to be executed until its result was absolutely needed. This
lazy execution model allows for very large, complex expressions to be built in one function then returned to the
outside world to be further processed and executed. Functions could be created inline and passed as arguments to other
functions, or constructed within functions and returned.</p>

<p>Sterling&rsquo;s tree-based structure naturally supported a prototype-based object model. To modify an expression tree, the
tree needed to create a copy of itself with any changes to it. All expressions, thus, were effective prototypes. This
also had the benefit of directly supporting immutability and helped to enforce a functional programming paradigm.</p>

<h2>What Could Have Been</h2>

<p>I intended Sterling to be a functional scripting language. In some ways, I was looking to create a JavaScript reboot
that clung closer to JavaScript&rsquo;s functional roots and would be used for general-purpose scripting.</p>

<p>Sterling&rsquo;s syntax was designed to be very terse, readable, and orthogonal. By that I mean everything in Sterling should
be an expression that can be used <a href="http://brandonbyars.com/2008/07/21/orthogonality/">virtually anywhere for anything</a>.
Because Sterling was based on lambdas, this worked particularly well for arguments expressions because arguments could
fold into the function call result on the left:</p>

<p>```haskell Consing a list by folding arguments, left-to-write
[] 1 2 3 4</p>

<blockquote><p>[1] 2 3 4
[1, 2] 3 4
[1, 2, 3] 4
[1, 2, 3, 4]
```</p></blockquote>

<p>This folding capability meant that Sterling could support very expressive programming styles. Any function could be
returned as the result of another function call and continue chaining against arguments. Sterling&rsquo;s terse syntax also
made defining functions very easy:</p>

<p><code>haskell Some basic functions in Sterling
identity = (x) -&gt; x
selfApply = (x) -&gt; x x
apply = (x y) -&gt; x y
selectFirst = (x y) -&gt; x
selectSecond = (x y) -&gt; y
conditional = (condition) -&gt; if condition.true? then selectFirst else selectSecond end
friday? = say $ conditional (today.is :friday) 'Yay Friday!' 'Awww...'
</code></p>

<p>Because Sterling was intended to be immutable, objects would be used to represent state and carry behavior to return
new state resulting from an operation:</p>

<p>```haskell Printing arguments from an immutable list iterator
main = (args) &ndash;></p>

<pre><code>print args.iterator // gets an Iterator
</code></pre>

<p>print = (iterator) &ndash;></p>

<pre><code>say unless iterator.empty? then
    printNext iterator 0
else
    'Empty iterator'
end
</code></pre>

<p>printNext = (iterator index) &ndash;></p>

<pre><code>unless iterator.empty? then
    "arg #{index} =&gt; #{iterator.current}\n" + printNext iterator.tail index.up
end
</code></pre>

<p>Iterator = (elements position) &ndash;> object {</p>

<pre><code>empty?: position &gt;= elements.length,
head: Iterator elements 0,
current: elements[position],
tail: iterator elements position.up,
</code></pre>

<p>}
```</p>

<p>Paul Hammant at one point suggested baking dependency injection <a href="http://paulhammant.com/blog/crazy-bob-and-type-safety-for-dependency-injection.html/">directly into a language</a>,
and even offered I do this in Sterling. This drove development of a metadata system in Sterling that could be used to
support metaprogramming and eventually dependency injection.</p>

<p>```haskell Meta attributes on expressions
@component { uses: [ :productionDb ] }
@useWhen (runtime &ndash;> runtime.env is :production)
Inventory = (db) &ndash;> object {</p>

<pre><code>numberOfItems: db.asInt $ db.scalarQuery "SELECT COUNT(*) FROM thingies",
priceCheck: (thingy) -&gt; db.asMoney $ db.scalarQuery "SELECT price FROM thingies WHERE id = :id" { id: thingy.id },
</code></pre>

<p>}</p>

<p>@provides :productionDb
createDb = &hellip;</p>

<p>@fake? true
@component { name: :Inventory }
@useWhen (runtime &ndash;> runtime.env is :development)
FakeInventory = object &ndash;> {</p>

<pre><code>numberOfItems: 0,
priceCheck: (thingy) -&gt; thingy.price,
</code></pre>

<p>}
```</p>

<p>The metadata system was very flexible and could support arbitrary meta annotations. The above metadata translates to
the following map structures at runtime:</p>

<p>```javascript What meta attributes look like if they were JavaScript
Inventory.meta = {</p>

<pre><code>"component": {
    "uses": [ "productionDb" ]
},
"useWhen": {
    "value": function (runtime) {
        return runtime["env"] == "production";
    }
}
</code></pre>

<p>};</p>

<p>createDb.meta = {</p>

<pre><code>"provides": {
    "value": "productionDb",
}
</code></pre>

<p>};</p>

<p>FakeInventory.meta = {</p>

<pre><code>"fake?": {
    "value": true
},
"component": {
    "name": "Inventory"
},
"useWhen": {
    "value": function (runtime) {
        return runtime["env"] == "development";
    }
}
</code></pre>

<p>};
```</p>

<p>I felt these functional features and expressive syntax would make for an enjoyable and productive programming
experience. The meta system in particular I felt could become quite powerful especially for customizing load-time
behavior of Sterling programs. However, some of my goals came with a few problems.</p>

<h2>The Problems</h2>

<h3>Speed</h3>

<p>Sterling is amazingly slow. A natural consequence of a tree-based language is that trees must be copied and modified
for many operations, no matter how &ldquo;trivial&rdquo; they may be (integer arithmetic, for example.) Recursive functions like
the <code>fibonacci</code> expression above had a particularly nasty characteristic of building enormous trees that took a lot of
time to reduce to single values.</p>

<p>The speed issues in Sterling were partially mitigated using <a href="http://loganmcgrath.com/blog/2013/06/17/sterling-with-memoization/">memoization</a>.</p>

<h3>Memoization: Blessing But Possibly A Curse</h3>

<p>Memoization increased the possibility for static state to hang around in an application. Applying arguments to an
object constructor, for instance, would return a previously-constructed object. I&rsquo;m not entirely sure what the total
impact of the &ldquo;object constructor problem&rdquo; could have been, as objects are not mutable, but I didn&rsquo;t like this
charateristic nonetheless. Immutability, however, wasn&rsquo;t entirely true (see &ldquo;Escaping The Matrix&rdquo; below).</p>

<p>Named expressions are persistent in memory. If a named expression took a large argument, or returned a large result,
then the total memory cost of a memoizing expression could become quite high over time.</p>

<h3>The Impacts Of Typelessness</h3>

<p>Types are actually quite nice to have, and I began to miss them quite a bit the more I worked on Sterling. While
Sterling is very flexible (because it has no types) it also has very poor support for polymorphism (because it has no
types). Want to do something else if you receive an <code>Asteroid</code> object rather than a <code>Spaceship</code> object?</p>

<p>The na&iuml;ve solution is to implement an if-case for each expected type:</p>

<p>```haskell
Spaceship = object {</p>

<pre><code>collideWith: (other) -&gt;
    if other.meta.name is 'Asteroid' then
        say 'Spaceship collided with an asteroid!'
    else if other.meta.name is 'Spaceship' then
        say 'Spaceships collide!'
    end
</code></pre>

<p>}</p>

<p>Asteroid = object {</p>

<pre><code>collideWith: (other) -&gt;
    if other.meta.name is 'Asteroid' then
        say 'Asteroids collide!'
    else if other.meta.name is 'Spaceship' then
        say 'Asteroid collided with a spaceship!'
    end
</code></pre>

<p>}
```</p>

<p>This is fragile, though, and the code is complex. What&rsquo;s worse, is there&rsquo;s no way to ensure that a method is receiving
an <code>Asteroid</code> and not another object that simply implements its API.  A better solution is to let the colliding object
select the proper method from the object it&rsquo;s colliding with:</p>

<p>```haskell
Spaceship = object {</p>

<pre><code>collideWith: (other) -&gt; other.collidedWithSpaceship self,
collideWithSpaceship: (spaceship) -&gt; say 'Spaceships collide!',
collideWithAsteroid: (asteroid) -&gt; say 'Spaceship collided with an asteroid!',
</code></pre>

<p>}</p>

<p>Asteroid = object {</p>

<pre><code>collideWith: (other) -&gt; other.collideWithAsteroid self,
collideWithSpaceship: (spaceship) -&gt; 'Asteroid collided with a spaceship!',
collideWithAsteroid: (asteroid) -&gt; 'Asteroids collide!',
</code></pre>

<p>}
```</p>

<p>This solution is better. It&rsquo;s also similar to implementing <a href="http://en.wikipedia.org/wiki/Visitor_pattern#Java_example">visitor pattern</a>
in Java. I still don&rsquo;t like it because there&rsquo;s no type safety and adding support for more types requires violating the
<a href="http://en.wikipedia.org/wiki/Open/closed_principle">open/closed principle</a>. For instance, in order for a <code>Bunny</code> to be
correctly collided-with, a <code>collidedWithBunny</code> method must be added to both <code>Spaceship</code> and <code>Asteroid</code>. Developers may
find it easier instead to allow the <code>Bunny</code> to masquerade as an asteroid:</p>

<p>```haskell Spaceship-eating Bunny
Bunny = object {</p>

<pre><code>collideWith: (other) -&gt; other.collideWithAsteroid self, // muahaha I'm an asteroid!
collidedWithSpaceship: (spaceship) -&gt; say 'NOM NOM NOM NOM!',
collidedWithAsteroid: (asteroid) -&gt; ...
</code></pre>

<p>}
```</p>

<p>This <a href="http://en.wikipedia.org/wiki/Multiple_dispatch#Java">single-dispatch behavior</a> means that for any argument
applied to a method name, the same method will be dispatched. In the case of Java, this is determined by the type of
a method&rsquo;s arguments at compile time. Adding new methods for similarly-typed arguments requires all client code be
recompiled. While Sterling may not have typing, it is still single-dispatch.</p>

<p>The lack of types became particularly painful when implementing arithmetic operations and compile-time analysis was
nearly impossible without collecting a great deal of superfluous metadata.</p>

<h3>Escaping The Matrix</h3>

<p>As I worked on Sterling, I required functionality that wasn&rsquo;t yet directly supportable in the language itself. I solved
this problem using the &ldquo;glue&rdquo; expression that could tie into a Java-based expression:</p>

<p><code>ruby sterling/collection/_base.ag
EmptyIterator = glue 'sterling.lang.builtin.EmptyIterator'
List = glue 'sterling.lang.builtin.ListConstructor'
Set = glue 'sterling.lang.builtin.SetConstructor'
Tuple = glue 'sterling.lang.builtin.TupleConstructor'
Map = glue 'sterling.lang.builtin.MapConstructor'
</code></p>

<p>For short-term problems, this option isn&rsquo;t too bad, but it allows the programmer to escape the immutable &ldquo;Matrix&rdquo; of
Sterling. For example, I implemented Sterling&rsquo;s collections as thin wrappers around Java collections, and allowed them
to be mutable. Actually, a lot of things in Sterling were mutable:</p>

<ul>
<li>Method collections on expressions</li>
<li>Object methods</li>
<li>Maps</li>
<li>Lists</li>
</ul>


<p>This, coupled with memoization, could cause a lot of issues with static state and had the potential to enable a lot of
bad design decisions for programs written in Sterling.</p>

<h2>The Good Parts</h2>

<p>Despite the baggage, there&rsquo;s a few takeaways!</p>

<p>Sterling&rsquo;s syntax is very small and terse. I particularly enjoyed not having to type a lot of parentheses, braces,
commas, and semicolons. Separating arguments by spaces allowed the language read like a book.</p>

<p>Most expressions can be delimited with whitespace alone, and because everything is an expression, objects could be
created inline and if-cases could be used as arguments.</p>

<p>Operators are just methods. Any object or expression can define a &ldquo;+&rdquo; operator and customize what it does. With
polymorphism supported with multi-methods, this can become an incredibly powerful feature.</p>

<p>Sterling also has the ability to define arbitrary metadata on any named expression. This metadata is gathered into a
<code>meta</code> attribute and can be inspected at runtime to support a sort of meta programming.</p>

<h2>What I&rsquo;m Carrying Forward</h2>

<p>I&rsquo;m now working on a new language project that will be borrowing Sterling&rsquo;s syntax. This time, however, I will be using
types. Algebraic data types hold a certain fascination for me, and I&rsquo;m interested in seeing what I can do with them. At
the very least, I do intend on using multi-methods for better polymorphism support.</p>

<p>I don&rsquo;t think I like declaring scope. It&rsquo;s verbose. Or declaring types. That should be restricted to places where it
impacts execution, like function signatures.</p>

<p>While Sterling&rsquo;s meta system didn&rsquo;t really go anywhere, I do intend on carrying it forward as a supplement to algebraic
types. I may even still bake in dependency injection because I hate all the typing required to tie together an
application.</p>

<p>I don&rsquo;t believe I will carry forward mandatory immutability, though I may support some form of &ldquo;immutability by
default&rdquo;.</p>

<p>Sterling&rsquo;s lazy evaluation caused a lot of headaches more than a few times. I&rsquo;ll probably not make any successor
language lazily evaluated because memoization becomes a near requirement in order to make lazy evaluation useful.</p>

<h2>My Holy Grail</h2>

<ul>
<li>A language that is interpreted and optionally compiled either AOT or JIT</li>
<li><a href="http://en.wikipedia.org/wiki/Type_inference">Inferred typing</a> as opposed to <a href="http://en.wikipedia.org/wiki/Nominative_type_system">nominal typing</a></li>
<li>At least psuedo-declarative</li>
<li>Dynamic to some degree</li>
<li>Easy to write, easy to read</li>
<li>Highly composable</li>
<li>Simple closures</li>
<li>First-class functions, if not first-class everything</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sterling With Memoization]]></title>
    <link href="http://loganmcgrath.com/blog/2013/06/17/sterling-with-memoization/"/>
    <updated>2013-06-17T04:26:00-07:00</updated>
    <id>http://loganmcgrath.com/blog/2013/06/17/sterling-with-memoization</id>
    <content type="html"><![CDATA[<p>In my <a href="/blog/2013/06/16/sterling-benchmarks/">last post</a> I wrote about performance in the
<a href="https://github.com/lmcgrath/sterling">Sterling</a> programming language with a basic benchmark. Today I&rsquo;m ticking off one
<strong>@TODO</strong> item: <a href="https://en.wikipedia.org/wiki/Memoization">Memoization</a>.</p>

<!--more-->


<p>Sterling now stores the results of each function/argument pair, returning respective results rather than forcing a
recalculation of an already-known value. I&rsquo;ve leveraged the benchmark from the previous post, and the difference in
execution speed is very pronounced:</p>

<p>``` bash The Results</p>

<h2>Java Benchmark</h2>

<p>Iteration 0: executions = 100; elapsed = 6 milliseconds
Iteration 1: executions = 100; elapsed = 4 milliseconds
Iteration 2: executions = 100; elapsed = 4 milliseconds
Iteration 3: executions = 100; elapsed = 4 milliseconds
Iteration 4: executions = 100; elapsed = 4 milliseconds
Iteration 5: executions = 100; elapsed = 4 milliseconds
Iteration 6: executions = 100; elapsed = 4 milliseconds
Iteration 7: executions = 100; elapsed = 4 milliseconds
Iteration 8: executions = 100; elapsed = 4 milliseconds</p>

<h2>Iteration 9: executions = 100; elapsed = 4 milliseconds</h2>

<p>Average for 10 iterations X 100 executions: 4 milliseconds</p>

<h2>Sterling Benchmark</h2>

<p>Iteration 0: executions = 100; elapsed = 648 milliseconds
Iteration 1: executions = 100; elapsed = 0 milliseconds
Iteration 2: executions = 100; elapsed = 1 milliseconds
Iteration 3: executions = 100; elapsed = 0 milliseconds
Iteration 4: executions = 100; elapsed = 0 milliseconds
Iteration 5: executions = 100; elapsed = 0 milliseconds
Iteration 6: executions = 100; elapsed = 0 milliseconds
Iteration 7: executions = 100; elapsed = 0 milliseconds
Iteration 8: executions = 100; elapsed = 0 milliseconds</p>

<h2>Iteration 9: executions = 100; elapsed = 0 milliseconds</h2>

<p>Average for 10 iterations X 100 executions: 64 milliseconds
```</p>

<p>Sterling without memoization required on average 0.079 seconds to calculate the 20th member of the Fibonacci sequence,
but with memoization, the amount of time shrinks to 0.006 seconds. The time penalty only applies the first time the
function is executed for a given argument, so call times become near-instantaneous.</p>

<h2>Sterling is faster than Java!</h2>

<p><strong>Not really.</strong> But it is if I fiddle with the benchmark variables a bit (:</p>

<p>By changing the benchmark to execute the Fibonacci function 1000 times for 100 iterations, something interesting
happens:</p>

<p>``` bash Fiddling with the benchmark</p>

<h2>Java Benchmark</h2>

<p>Iteration 0: executions = 1000; elapsed = 42 milliseconds
Iteration 1: executions = 1000; elapsed = 39 milliseconds
Iteration 2: executions = 1000; elapsed = 38 milliseconds
Iteration 3: executions = 1000; elapsed = 39 milliseconds
Iteration 4: executions = 1000; elapsed = 39 milliseconds
Iteration 5: executions = 1000; elapsed = 39 milliseconds
Iteration 6: executions = 1000; elapsed = 41 milliseconds
Iteration 7: executions = 1000; elapsed = 40 milliseconds
Iteration 8: executions = 1000; elapsed = 38 milliseconds
Iteration 9: executions = 1000; elapsed = 38 milliseconds
&hellip;</p>

<h2>Iteration 99: executions = 1000; elapsed = 39 milliseconds</h2>

<p>Average for 100 iterations X 1000 executions: 39 milliseconds</p>

<h2>Sterling Benchmark</h2>

<p>Iteration 0: executions = 1000; elapsed = 629 milliseconds
Iteration 1: executions = 1000; elapsed = 0 milliseconds
Iteration 2: executions = 1000; elapsed = 0 milliseconds
Iteration 3: executions = 1000; elapsed = 0 milliseconds
Iteration 4: executions = 1000; elapsed = 0 milliseconds
Iteration 5: executions = 1000; elapsed = 0 milliseconds
Iteration 6: executions = 1000; elapsed = 0 milliseconds
Iteration 7: executions = 1000; elapsed = 0 milliseconds
Iteration 8: executions = 1000; elapsed = 1 milliseconds
Iteration 9: executions = 1000; elapsed = 0 milliseconds
&hellip;</p>

<h2>Iteration 99: executions = 1000; elapsed = 0 milliseconds</h2>

<p>Average for 100 iterations X 1000 executions: 6 milliseconds
```</p>

<h3>This benchmark smells funny</h3>

<p>Yes, the performance in this benchmark is very contrived. But this does present an interesting potential property of
applications written in Sterling: If an application performs a great deal of repeated calculations, it will run faster
over time. A quick glance at the second bench mark will show that Java is performing the calculation every single time
it is called, whereas Sterling only requires the first call and then it stores the result. This suggests <strong>O(1)</strong> vs.
<strong>O(n)</strong> time complexity in Sterling&rsquo;s favor.</p>

<p>You won&rsquo;t get this sort of performance for a web application because of their side effect-driven nature, but for number
crunching Sterling may very well be a good idea.</p>

<h2>@TODO</h2>

<h3>How does memoization impact memory?</h3>

<p>Obviously, those calculated values get stored somewhere, and somewhere means memory is being used. I should perform
another benchmark comparing memory requirements of the Fibonacci algorithm between pure Java and Sterling.</p>

<h3>What if I don&rsquo;t want memoization for a particular function?</h3>

<p>There may be some cases where you want to recalculate a value for a known argument. For example, if I query a database
I shouldn&rsquo;t necessarily  expect the same result each time. Sterling should give an easy way of signalling that a
function should not leverage memoization.</p>

<h2>Links</h2>

<ul>
<li><a href="https://github.com/lmcgrath/sterling/commit/7d69d49a911d2d916701fa973e02ffabe82afe9d">Commit containing memoization changes</a></li>
<li><a href="https://github.com/lmcgrath/sterling/blob/5c879ece28194fdbc36ed5dff2a760d6a38a4033/src/test/java/sterling/math/FibonacciBenchmarkTest.java">Benchmark showing O(1) complexity</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sterling Benchmarks]]></title>
    <link href="http://loganmcgrath.com/blog/2013/06/16/sterling-benchmarks/"/>
    <updated>2013-06-16T21:12:00-07:00</updated>
    <id>http://loganmcgrath.com/blog/2013/06/16/sterling-benchmarks</id>
    <content type="html"><![CDATA[<p>Since <a href="https://github.com/lmcgrath/sterling/tree/8b58ce4d4b080b353f7870ec0c0c30639fb2fa7b">mid January</a>, I’ve been
developing a functional scripting language I call <a href="https://github.com/lmcgrath/sterling">Sterling</a>. In the past few
weeks, Sterling has become nearly usable, but it doesn’t seem to be very fast. So this weekend, I’ve taking the time to
create a simple (read: na&iuml;ve) benchmark.</p>

<p>The benchmark uses a <a href="http://en.wikipedia.org/wiki/Dynamic_programming#Fibonacci_sequence">recursive algorithm</a> to
calculate the Nth member of the <a href="http://en.wikipedia.org/wiki/Fibonacci_sequence">Fibonacci sequence</a>. I’ve implemented
both Sterling and Java versions of the algorithm and I will be benchmarking each for comparison.</p>

<!--more-->


<p>``` haskell Sterling Implementation
fibonacci = n &ndash;> if n = 0 then 0</p>

<pre><code>             else if n = 1 then 1
             else fibonacci (n - 1) + fibonacci (n - 2)
</code></pre>

<p>```</p>

<p>``` java Java Implementation
static int fibonacci(int n) {</p>

<pre><code>if (n == 0) {
    return 0;
} else if (n == 1) {
    return 1;
} else {
    return fibonacci(n - 1) + fibonacci(n - 2);
}
</code></pre>

<p>}
```</p>

<h3>Why was the Fibonacci sequence chosen for the benchmark?</h3>

<p>The algorithm for calculating the Nth member of the Fibonacci sequence has two key traits:</p>

<ul>
<li>It’s recursive</li>
<li>It has O(2<sup>n</sup>) complexity</li>
</ul>


<p>Sterling as of right now performs zero optimizations, so I’m assuming this algorithm will bring out Sterling’s
worst performance characteristics (muahahaha).</p>

<h2>The benchmark execution plan</h2>

<p>I’m using a very basic benchmark excluding Sterling’s compilation overhead and comparing the results to native Java. I
will execute the Fibonacci algorithm 100 times for 10 iterations, providing an average of the time elapsed for each
iteration.</p>

<p>``` java Benchmark Pseudo-Java&trade;
Expression input = IntegerConstant(20);
Expression sterlingFibonacci = load(&ldquo;sterling/math/fibonacci&rdquo;);</p>

<p>void javaBenchmark() {</p>

<pre><code>List&lt;Interval&gt; intervals;
int value = input.getValue();
for (int i : iterations) {
    long startTime = currentTimeMillis();
    for (int j : executions) {
        fibonacci(value);
    }
    intervals.add(currentTimeMillis() - startTime);
    printIteration(i, intervals.last());
}
printAverage(intervals);
</code></pre>

<p>}</p>

<p>void sterlingBenchmark() {</p>

<pre><code>List&lt;Interval&gt; intervals;
for (int i : iterations) {
    long startTime = currentTimeMillis();
    for (int j : executions) {
        sterlingFibonacci.apply(input).evaluate();
    }
    intervals.add(currentTimeMillis() - startTime);
    printIteration(i, intervals.last());
}
printAverage(intervals);
</code></pre>

<p>}
```</p>

<h2>The benchmark results</h2>

<p>``` bash The Results</p>

<h2>Java Benchmark</h2>

<p>Iteration 0: executions = 100; elapsed = 4 milliseconds
Iteration 1: executions = 100; elapsed = 4 milliseconds
Iteration 2: executions = 100; elapsed = 4 milliseconds
Iteration 3: executions = 100; elapsed = 4 milliseconds
Iteration 4: executions = 100; elapsed = 4 milliseconds
Iteration 5: executions = 100; elapsed = 4 milliseconds
Iteration 6: executions = 100; elapsed = 4 milliseconds
Iteration 7: executions = 100; elapsed = 4 milliseconds
Iteration 8: executions = 100; elapsed = 4 milliseconds</p>

<h2>Iteration 9: executions = 100; elapsed = 4 milliseconds</h2>

<p>Average for 10 iterations X 100 executions: 4 milliseconds</p>

<h2>Sterling Benchmark</h2>

<p>Iteration 0: executions = 100; elapsed = 8,152 milliseconds
Iteration 1: executions = 100; elapsed = 7,834 milliseconds
Iteration 2: executions = 100; elapsed = 7,873 milliseconds
Iteration 3: executions = 100; elapsed = 7,873 milliseconds
Iteration 4: executions = 100; elapsed = 7,910 milliseconds
Iteration 5: executions = 100; elapsed = 7,973 milliseconds
Iteration 6: executions = 100; elapsed = 7,927 milliseconds
Iteration 7: executions = 100; elapsed = 7,793 milliseconds
Iteration 8: executions = 100; elapsed = 7,912 milliseconds</p>

<h2>Iteration 9: executions = 100; elapsed = 7,986 milliseconds</h2>

<p>Average for 10 iterations X 100 executions: 7,923 milliseconds
```</p>

<h3>Immediate conclusions:</h3>

<p>Sterling is <em><strong>REALLY</strong></em> slow!</p>

<p>Sterling executes directly against an abstract syntax tree representing operations and data. This tree is generally
immutable, so the execution is performed by effectively rewriting the tree to reduce each node into an “atomic”
expression, such as an integer constant or lambda (which can’t be further reduced without an applied argument).</p>

<p>References to functions are inserted into the tree by copying the function’s tree into the reference’s node. The
function is then evaluated with a given argument to reduce the tree to a single node. These copy-and-reduce operations
are very costly and are a likely reason for Sterling’s poor performance.</p>

<h2>@TODO</h2>

<h3>Memoization</h3>

<p>Copying and reducing a function tree for an argument is expensive. These operations should not need to be performed
more than once for any function and argument pair.</p>

<h3>Bytecode perhaps?</h3>

<p>Given the shear amount of recursion and method calls being performed to execute Sterling, does it makes sense to
compile the syntax tree into a bytecode that can be executed in a loop?</p>

<h2>Links</h2>

<ul>
<li><a href="https://github.com/lmcgrath/sterling">Sterling GitHub Project</a></li>
<li><a href="https://github.com/lmcgrath/sterling/blob/post_20130616_sterling_benchmark/src/test/java/sterling/math/FibonacciBenchmarkTest.java">Benchmark Code</a></li>
<li><a href="https://github.com/lmcgrath/sterling/blob/post_20130616_sterling_benchmark/src/main/resources/sterling/math/_base.ag">Sterling Fibonacci Implementation</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
